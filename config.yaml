# Primary backend configurations for LLM API endpoints
primary_backends:
  # First backend configuration
  - name: LLM1  # Identifier for the first backend
    url: https://api.openai.com/v1  # API endpoint URL
    model: ""  # Model to use (if blank, must be specified in request)
  
  # Second backend configuration (not currently used)
  - name: LLM2  # Identifier for the second backend
    url: ""  # API endpoint URL (not configured)
    model: ""  # Model to use (not configured)

# Global settings
settings:
  timeout: 30  # Request timeout in seconds 